{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960a917d-0231-4b25-9bad-e68e70ca7a12",
   "metadata": {},
   "source": [
    "# Homework 3 - Outputs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51ad5b7-101d-413a-b240-aa5356f2a2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functions_hw3 as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0314874-9d5c-4cc3-9ae0-e6c748c56baa",
   "metadata": {},
   "source": [
    "### List of paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782df6c1-f70d-4011-8497-ed20a48d4c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_list_anime = \"list_anime.txt\"\n",
    "url_of_single_page = \"https://myanimelist.net/topanime.php?limit=\"\n",
    "path_page_general = \"Anime/Page\"\n",
    "path_documents_file = \"documents.tsv\"\n",
    "path_vocabulary_file = \"vocabulary.json\"\n",
    "path_index_file = \"Anime/index.json\"\n",
    "path_documents_ex_3 = \"Anime/documents_ex_3.tsv\"\n",
    "path_vocabulary_title_file = \"/Anime/vocabulary_title.json\"\n",
    "path_index_title_file =\"Anime/index_title.json\"\n",
    "path_inverted_index_file=\"Anime/inverted_index.json\"\n",
    "path_inverted_index_title_file = \"Anime/inverted_index_title.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d875ed-22b1-4986-a1c1-375af8ec3307",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc0cc2-e356-407d-a9e9-2d86bd3f0697",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of animes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed614a77-1678-4709-8e75-46afd31b3041",
   "metadata": {},
   "source": [
    "#### Write a file with all anime url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cab7e-d65a-46bd-b8d7-cf12d978ca34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_list_anime(path_list_anime, url_of_single_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da2daf-6702-4170-a870-9208d2e31c07",
   "metadata": {},
   "source": [
    "### 1.2. Crawl animes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf19f7-c245-4a03-93e3-c590b9a29ca3",
   "metadata": {},
   "source": [
    "#### Download all html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7788ac-3446-480e-99ec-ee037be0e859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.download_html(path_list_anime, path_page_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca7e41-e1b2-4c08-9737-5c8fe77db637",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afce736-8d4b-4c83-bcc8-d0f46f3d87ec",
   "metadata": {},
   "source": [
    "#### This function will create 3 different files: \n",
    "- one .tsv file for each anime\n",
    "- one .tsv file with 3 most important information for all animes: Title, Description, Url\n",
    "- one .tsv file with 4 most important information for all animes: Title, Description, Url, AnimeScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc36cd-e88d-425d-bfd2-2bcb82d6c7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.create_tsvs(path_list_anime, path_page_general, path_documents_file, path_documents_ex_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a126a-57e6-4fd9-ad38-f930c3f6a512",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94445db4-35b4-476f-b027-8e179048b00e",
   "metadata": {},
   "source": [
    "#### Create pandas dataframe with important information from previous written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf9f7f-77c2-43f1-8ac6-0d6d5f829357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.df_from_3_information_file(path_documents_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14caaa7e-ee52-453f-8468-6814fd84a631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.df_from_4_information_file(path_documents_ex_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7cb4e-ca8b-4cc3-89dc-505e2a143700",
   "metadata": {},
   "source": [
    "#### Text cleaning:\n",
    "\n",
    "In order we will do the following operations:\n",
    "\n",
    "- Remove \"[Written by MAL Rewrite]\" at the end of each description\n",
    "\n",
    "- Remove Contractions (for example \"won't\" become \"will not\" and \"don't\" become \"do not\")\n",
    "\n",
    "- Make all characters lower case (for example \"Hello\" become \"hello\")\n",
    "\n",
    "- Remove dashes\n",
    "\n",
    "- Remove ordinal numbers (for example 1st, 2nd, ...)\n",
    "\n",
    "- Remove stopwords (adding to stopwords frequent words that appear in descriptions, for example \"character\", \"end\") \n",
    "\n",
    "- Remove punctuation\n",
    "\n",
    "- Stemming\n",
    "\n",
    "All the functions are implemented in functions_hw3.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72846574-943c-4b80-809d-731528c9e118",
   "metadata": {},
   "source": [
    "#### Function that apply text cleaning on a precise column of a pandas dataframe and returns a pandas dataframe with only this cleaned column. \n",
    "The parameter \"original_df\" is one of the two obtained with previous functions \"df_from_3_information_file\" and \"df_from_4_information_file\".\n",
    "\n",
    "The parameter \"column_type\" accept a column with some text or string inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39228ea7-7203-438d-a533-979532b55439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.clean_df(original_df, column_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23f367-18f5-4661-9c79-3137d9f4e74b",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d74a3-fd52-4c2a-9b47-9eb0942e6198",
   "metadata": {},
   "source": [
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b14d9-544a-49c6-aaee-b5b47a465fc8",
   "metadata": {},
   "source": [
    "#### Create vocabulary and first inverted index (named index for simplicity) and save them as .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea567c-d3bb-48ce-bf9e-87e8ec1c060e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_vocabulary(path_vocabulary_file, df_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7cf4d-2932-437e-9115-1d8a58eace86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_index(vocabulary, path_index_file, df_descriptions):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfef105-fc0f-407f-8415-08c3968ae887",
   "metadata": {},
   "source": [
    "#### Functions to read vocabulary and index from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82245fe-6e2e-41b2-8661-b078e6a47b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.read_vocabulary(path_vocabulary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e39b73-fe41-4724-9f36-c5aac303b588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.read_index(path_index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d10a7-e2fd-49b1-b724-661de7f713c0",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e630d86-80fa-4e00-822d-678e20c3ea5a",
   "metadata": {},
   "source": [
    "#### Execute the conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05961c-f677-484b-9633-0ebc925ef169",
   "metadata": {},
   "source": [
    "This function takes in input a string as \"query\", the vocabulary and the associated index for anime descriptions.\n",
    "\n",
    "It returns a pandas.Dataframe object with all the anime that contains all the words in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce06e56-d442-417a-b4b9-18c39315ce44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"robot\"\n",
    "vocabulary = f.read_vocabulary(path_vocabulary_file)\n",
    "index = f.read_index(path_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67737308-4905-406e-ad69-f2f1f6e3f44b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>https://myanimelist.net/anime/28977/GintamaÂ°\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Made in Abyss</td>\n",
       "      <td>The Abyssâa gaping chasm stretching down into ...</td>\n",
       "      <td>https://myanimelist.net/anime/2921/Ashita_no_J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Neon Genesis Evangelion: The End of Evangelion</td>\n",
       "      <td>Shinji Ikari is left emotionally comatose afte...</td>\n",
       "      <td>https://myanimelist.net/anime/38474/Yuru_Campâ³...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Nichijou</td>\n",
       "      <td>Nichijou primarily focuses on the daily antics...</td>\n",
       "      <td>https://myanimelist.net/anime/31181/Owarimonog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Tengen Toppa Gurren Lagann</td>\n",
       "      <td>Simon and Kamina were born and raised in a dee...</td>\n",
       "      <td>https://myanimelist.net/anime/34591/Natsume_Yu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         animeTitle  \\\n",
       "0                  Fullmetal Alchemist: Brotherhood   \n",
       "45                                    Made in Abyss   \n",
       "90   Neon Genesis Evangelion: The End of Evangelion   \n",
       "124                                        Nichijou   \n",
       "62                       Tengen Toppa Gurren Lagann   \n",
       "\n",
       "                                      animeDescription  \\\n",
       "0    After a horrific alchemy experiment goes wrong...   \n",
       "45   The Abyssâa gaping chasm stretching down into ...   \n",
       "90   Shinji Ikari is left emotionally comatose afte...   \n",
       "124  Nichijou primarily focuses on the daily antics...   \n",
       "62   Simon and Kamina were born and raised in a dee...   \n",
       "\n",
       "                                                   Url  \n",
       "0     https://myanimelist.net/anime/28977/GintamaÂ°\\r\\n  \n",
       "45   https://myanimelist.net/anime/2921/Ashita_no_J...  \n",
       "90   https://myanimelist.net/anime/38474/Yuru_Campâ³...  \n",
       "124  https://myanimelist.net/anime/31181/Owarimonog...  \n",
       "62   https://myanimelist.net/anime/34591/Natsume_Yu...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.execute_query(query, vocabulary, index, path_documents_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce3f07-53a2-45f7-a2a5-cb53f2ec140b",
   "metadata": {},
   "source": [
    "### 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb56df-47f7-4e90-afd2-819d742f4700",
   "metadata": {},
   "source": [
    "### 2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4a2ad-f978-4133-ad2f-16e2bdb0dbd3",
   "metadata": {},
   "source": [
    "#### Create second inverted index (named inverted_index for simplicity) and save it as .json file\n",
    "\n",
    "This function take similar inputs as previuos write files functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6aa8b-122a-40b6-a6a0-dcf2ac2f2a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_inverted_index (original_df, vocabulary, index, column_type, path_inverted_index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941d36d-c019-4817-8af5-016e70d5115b",
   "metadata": {},
   "source": [
    "#### Function to read inverted index from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc5d54-a5d4-4478-b0ff-d0261b662d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.read_inverted_index(path_inverted_index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7a27f-c51f-41ca-8e82-0a16cc292724",
   "metadata": {},
   "source": [
    "#### Function that return the list of indexes of conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0c3d6-47c9-45c4-8e66-022cbf3abaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.docs_contains_query(query, vocabulary, index, path_documents_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67089252-6bd2-4cad-b47c-6197806f793d",
   "metadata": {},
   "source": [
    "#### Given a query, we calculate some vectors as numpy array for optimization (based on \"animeDescription\" column in the dataframe):\n",
    "- query vector of lenght equals to the lenght of vocabulary, with ones if the word is present and zeros otherwise **function get_query_vector(query, vocabulary)**\n",
    "- doc vector for each documents in the total original cleaned dataframe **get_doc_vector(n_row_doc, df_cleaned, vocabulary, inverted_index, column_type)**\n",
    "- score as cosine similarity between query vector and the selected document vector in loop **calc_score(q_vector, doc_vector)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1e010-9e83-4db4-a394-f11cdeed846e",
   "metadata": {},
   "source": [
    "### 2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e92d94-2615-4ae8-bb19-3e219477d941",
   "metadata": {},
   "source": [
    "#### Then it's possible to execute the query\n",
    "\n",
    "It will return a list of documents, ranked by their Cosine Similarity with respect to the query entered in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c83d803-fe1b-4c99-a040-be772ecaafb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"robot\"\n",
    "k = 5\n",
    "column_type = \"animeDescription\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c00dd1-fe1b-484d-8c96-a360a93d0faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_df = f.df_from_3_information_file(path_documents_file)\n",
    "df_cleaned = f.clean_df(original_df, column_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91570a92-d761-4d3e-a1fa-f290b9908dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inverted_index = f.read_inverted_index(path_inverted_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e44a71d-9fdd-43e0-8688-570eb406d702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity animeDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Nichijou</td>\n",
       "      <td>Nichijou primarily focuses on the daily antics...</td>\n",
       "      <td>https://myanimelist.net/anime/31181/Owarimonog...</td>\n",
       "      <td>0.080656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Made in Abyss</td>\n",
       "      <td>The Abyssâa gaping chasm stretching down into ...</td>\n",
       "      <td>https://myanimelist.net/anime/2921/Ashita_no_J...</td>\n",
       "      <td>0.051465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Neon Genesis Evangelion: The End of Evangelion</td>\n",
       "      <td>Shinji Ikari is left emotionally comatose afte...</td>\n",
       "      <td>https://myanimelist.net/anime/38474/Yuru_Campâ³...</td>\n",
       "      <td>0.050071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Tengen Toppa Gurren Lagann</td>\n",
       "      <td>Simon and Kamina were born and raised in a dee...</td>\n",
       "      <td>https://myanimelist.net/anime/34591/Natsume_Yu...</td>\n",
       "      <td>0.050121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>https://myanimelist.net/anime/28977/GintamaÂ°\\r\\n</td>\n",
       "      <td>0.049967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         animeTitle  \\\n",
       "124                                        Nichijou   \n",
       "45                                    Made in Abyss   \n",
       "90   Neon Genesis Evangelion: The End of Evangelion   \n",
       "62                       Tengen Toppa Gurren Lagann   \n",
       "0                  Fullmetal Alchemist: Brotherhood   \n",
       "\n",
       "                                      animeDescription  \\\n",
       "124  Nichijou primarily focuses on the daily antics...   \n",
       "45   The Abyssâa gaping chasm stretching down into ...   \n",
       "90   Shinji Ikari is left emotionally comatose afte...   \n",
       "62   Simon and Kamina were born and raised in a dee...   \n",
       "0    After a horrific alchemy experiment goes wrong...   \n",
       "\n",
       "                                                   Url  \\\n",
       "124  https://myanimelist.net/anime/31181/Owarimonog...   \n",
       "45   https://myanimelist.net/anime/2921/Ashita_no_J...   \n",
       "90   https://myanimelist.net/anime/38474/Yuru_Campâ³...   \n",
       "62   https://myanimelist.net/anime/34591/Natsume_Yu...   \n",
       "0     https://myanimelist.net/anime/28977/GintamaÂ°\\r\\n   \n",
       "\n",
       "     Similarity animeDescription  \n",
       "124                     0.080656  \n",
       "45                      0.051465  \n",
       "90                      0.050071  \n",
       "62                      0.050121  \n",
       "0                       0.049967  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.execute_similarity_query(query, k, df_cleaned, vocabulary, index, inverted_index, original_df, path_documents_file, column_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927b262-f103-4f49-8b87-8ef3d29f6af6",
   "metadata": {},
   "source": [
    "## 3. Define a new score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc4dde-3553-42d0-b94c-fe31e79ac6d8",
   "metadata": {},
   "source": [
    "#### Explanation of the new score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d244f1-c47c-4c92-97ab-61e2f7997fd8",
   "metadata": {},
   "source": [
    "We decided to build the new score based on a weighted average between cosine score calculated on anime descriptions, cosine distance on anime title and considering the field anime Score (normalized)\n",
    "\n",
    "We build a function with multiple chance to choose the score (the user can activate a sort of filter, deciding which fields will be used in the final score calculation between these two new).\n",
    "\n",
    "In the weighted average, if the cosine distance of anime title is considered, it will have a weight equals to **2**. If the anime score is considered it will have weight equals one, but its value is rescaled divided by its max value (**10**). In both cases cosine score calculated on anime descriptions will have weight equals to **1**\n",
    "\n",
    "By default, the filters are set to false, so the score is equal to the previous excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b5f56-797b-4dc1-920b-d53ddc653581",
   "metadata": {},
   "source": [
    "#### Before execution of the query we have to write (and read after of course) vocabulary, index and inverted index for \"animeTitle\" field with the follwing methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8845d-9b09-4f96-9501-d16642594024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_vocabulary_title(path_vocabulary_title_file, df_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af94aa-2105-4be7-8bfe-4743f603e4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_index_title(vocabulary_title, path_index_title_file, df_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e0f74-e0e8-479f-8647-364cdd12cac4",
   "metadata": {},
   "source": [
    "Passing as column_type : \"animeTitle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c95004-ff09-4217-8181-b6bcb0454d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_inverted_index (original_df, vocabulary, index, column_type, path_inverted_index_title_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34abe36c-4171-45cc-8f43-f4b45e81bf22",
   "metadata": {},
   "source": [
    "#### Execute the query and show results as previous excercises in a pandas dataframe structure, with the new column \"FinalScore\" which will show up the total final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae21f478-2175-45d7-9bd4-53b869f1fd36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"robot\"\n",
    "k = 2\n",
    "prior_title = True\n",
    "prior_a_score = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bbde983-5f7d-4064-b4b7-e42c52ae050e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_df = f.df_from_4_information_file(path_documents_ex_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "002a7812-2ed7-4280-80a8-35d7efe3175f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary = f.read_vocabulary(path_vocabulary_file)\n",
    "index = f.read_index(path_index_file)\n",
    "inverted_index = f.read_inverted_index(path_inverted_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ed05438-5291-4dd9-94dd-75b9d82f3c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary_title = f.read_vocabulary(path_vocabulary_title_file)\n",
    "index_title = f.read_index(path_index_title_file)\n",
    "inverted_index_title = f.read_inverted_index(path_inverted_index_title_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e05a369a-c69a-4612-b010-8ddf16457ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "      <th>animeScore</th>\n",
       "      <th>Similarity animeDescription</th>\n",
       "      <th>Similarity animeTitle</th>\n",
       "      <th>FinalScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Nichijou</td>\n",
       "      <td>Nichijou primarily focuses on the daily antics...</td>\n",
       "      <td>https://myanimelist.net/anime/31181/Owarimonog...</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.080656</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>https://myanimelist.net/anime/28977/GintamaÂ°\\r\\n</td>\n",
       "      <td>9.16</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             animeTitle  \\\n",
       "index                                     \n",
       "124                            Nichijou   \n",
       "0      Fullmetal Alchemist: Brotherhood   \n",
       "\n",
       "                                        animeDescription  \\\n",
       "index                                                      \n",
       "124    Nichijou primarily focuses on the daily antics...   \n",
       "0      After a horrific alchemy experiment goes wrong...   \n",
       "\n",
       "                                                     Url  animeScore  \\\n",
       "index                                                                  \n",
       "124    https://myanimelist.net/anime/31181/Owarimonog...        8.46   \n",
       "0       https://myanimelist.net/anime/28977/GintamaÂ°\\r\\n        9.16   \n",
       "\n",
       "       Similarity animeDescription  Similarity animeTitle  FinalScore  \n",
       "index                                                                  \n",
       "124                       0.080656                      0    0.026885  \n",
       "0                         0.049967                      0    0.016656  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.execute_new_score_query(query, k, vocabulary, index, inverted_index, vocabulary_title, index_title, inverted_index_title, \n",
    "                            path_documents_file, path_documents_ex_3, prior_title = True, prior_a_score = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12807805-757f-4f2e-be9b-49e9bbfe5dc0",
   "metadata": {},
   "source": [
    "## 5. Algorithmic question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b09eb5-3e70-41ec-896d-9032eea0808f",
   "metadata": {},
   "source": [
    "#### * Loop for all elements in requests\n",
    "* Maintain two sums include and exclude\n",
    "* include = Max sum including the previous element\n",
    "* exclude = Max sum excluding the previous element\n",
    " \n",
    " \n",
    "* for i in requests:\n",
    "    * include = exclude + requests[i]\n",
    "    * exclude = max(include,exclude)\n",
    "\n",
    "\n",
    "* for selecting optimal values we will use \n",
    "\n",
    "* if sum(list) == exclude\n",
    "* list.append(requests[i])\n",
    "\n",
    "\n",
    "* during adding value we will have 3 type of situation \n",
    "1. sum(list) == exclude\n",
    "2. sum(list-last element) == exclude\n",
    "3. sum(list-last 2 element) == exclude\n",
    "\n",
    "\n",
    "* initially\n",
    "\n",
    "* requests = [30, 40, 25, 50, 30, 20]\n",
    "\n",
    "\n",
    "* include = 30                                \n",
    "* exclude = 0                                 \n",
    "* list1 = [30]\n",
    "* list2 = [0]\n",
    "\n",
    "* include = exclude + requests[i]\n",
    "* exclude = max(include,exclude)\n",
    "\n",
    "\n",
    "* for i = 1 (element is 40)\n",
    "* include = (exclude + requests[i]) = 40      \n",
    "* exclude = max(30, 0) = 30                   \n",
    "* list1 = [30]\n",
    "* list2 = [40]\n",
    "\n",
    "\n",
    "* for i = 2 (element is 25)                   \n",
    "* include = (exclude + requests[i]) = 55      \n",
    "* exclude = max(40, 30) = 40                  \n",
    "* list1 = [30,25]\n",
    "* list2 = [40]\n",
    "\n",
    "\n",
    "* for i = 3 (element is 50)\n",
    "* include = (exclude + requests[i]) = 90      \n",
    "* exclude = max(55, 40) = 55                  \n",
    "* list1 = [30,25]\n",
    "* list2 = [40,50]\n",
    "\n",
    "\n",
    "* for i = 4 (element is 30)                   \n",
    "* include = (exclude + requests[i]) = 85      \n",
    "* exclude = max(90, 55) = 90                  \n",
    "* list1 = [30,25,30]\n",
    "* list2 = [40,50]\n",
    "\n",
    "\n",
    "* for i = 5 (element is 20)\n",
    "* include = (exclude + requests[i]) = 110     \n",
    "* exclude = max(85, 90) = 90                  \n",
    "* list1 = [30,25,30]\n",
    "* list2 = [40,50,20]\n",
    "\n",
    "\n",
    "* 20 is the last element, So answer is max(110,90) = 110\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1c212381-dd86-4dbe-89f4-67b6d34b7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return max sum such that no two elements are consecutive \n",
    "def find_max_time(requests):\n",
    "    #creating include and exclude\n",
    "    include = 0 \n",
    "    exclude = 0\n",
    "    #creating 2 lists for adding values\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    #creating 2 lists for adding i+2 index value when we test i+3 index\n",
    "    list1_1 = []\n",
    "    list2_1 = []\n",
    "    #we have to know the len of request in order to pick i+2 or i+3 in last element\n",
    "    requests_len = len(requests)\n",
    "    \n",
    "\n",
    "    for i, j in zip(requests, range(requests_len)):\n",
    "        # Current max excluding i\n",
    "        new_exclude = exclude if exclude > include else include\n",
    "\n",
    "        # Storing value as a list\n",
    "        # before we apply \"include = exclude + requests[i]\" we find list that sum  is equal to exclude\n",
    "        if sum(list1) == exclude:\n",
    "            list1.append(i)\n",
    "        elif sum(list2) == exclude:\n",
    "            list2.append(i)\n",
    "\n",
    "        # if none of them is equal to exclude we check it without last value of list    \n",
    "        elif sum(list1[:-1]) == exclude:\n",
    "            list1_1.append(list1[-1]) # adding last value to list1_1\n",
    "            list1 = list1[:-1] # removing last value \n",
    "            list1.append(i) # adding current i\n",
    "            if len(list1_1)>1: # checking stored value in list 1_1 \n",
    "                list1_1 = list1_1[1:] #remove firs elemet it always store 1 element\n",
    "            #Last element control\n",
    "            if j == requests_len-1: # if i is last element\n",
    "                if sum(list1[:-1] + list1_1) > sum(list1): #compare last element and previous element which is we stored in list1_1\n",
    "                    list1 = list1[:-1] #  change last element\n",
    "                    list1 = list1 + list1_1[:1]\n",
    "                    \n",
    "        # applying same steps for list2 and list2_1\n",
    "        elif sum(list2[:-1]) == exclude:\n",
    "            list2_1.append(list2[-1]) # adding last value to list2_1\n",
    "            list2 = list2[:-1] # removing last value \n",
    "            list2.append(i) # adding current i\n",
    "            if len(list2_1)>1: # checking stored value in list 2_1 \n",
    "                list2_1 = list2_1[1:] #remove firs elemet it always store 1 element\n",
    "            #Last element control\n",
    "            if j == requests_len-1: # if i is last element\n",
    "                if sum(list2[:-1] + list2_1) > sum(list2): #compare last element and previous element which is we stored in list1_1\n",
    "                    list2 = list2[:-1] #  change last element\n",
    "                    list2 = list2 + list2_1[:1]                \n",
    "\n",
    "        # if none of previous conditions is true we replace last value in list with value is stored in list1_1            \n",
    "        elif sum(list1[:-1]+list1_1) == exclude:\n",
    "            list1_1.append(list1[-1]) #add last value to list1_1\n",
    "            list1 = list1[:-1]\n",
    "            list1 = list1 + list1_1[:1] #replace last value of list1 with first value of list1_1\n",
    "            list1.append(i)\n",
    "            if len(list1_1)>1:\n",
    "                list1_1 = list1_1[1:] #remove 1st element from list1_1 whish is added to  list1\n",
    "                \n",
    "            #Last element control\n",
    "            if j == requests_len-1: # check if i is last element\n",
    "                if sum(list1[:-2] + list1_1) > sum(list1): # compare list with raplacing last value\n",
    "                    list1 = list1[:-2]\n",
    "                    list1 = list1 + list1_1 #adding back previous value\n",
    "                    \n",
    "        # for list2\n",
    "        else:\n",
    "            list2_1.append(list2[-1])#add last value to list2_1\n",
    "            list2 = list2[:-1]\n",
    "            list2 = list2 + list2_1[:1]#replace last value of list2 with first value of list2_1\n",
    "            list2.append(i)\n",
    "            if len(list2_1)>1:\n",
    "                list2_1 = list2_1[1:] #remove 1st element from list2_1 whish is added to  list2\n",
    "                \n",
    "            #Last element control\n",
    "            if j == requests_len-1:# check if i is last element\n",
    "                if sum(list2[:-2] + list2_1) > sum(list2):# compare list with raplacing last value\n",
    "                    list2 = list2[:-2]\n",
    "                    list2 = list2 + list2_1 #adding back previous value\n",
    "\n",
    "        # Current max including i\n",
    "        include = exclude + i \n",
    "        exclude = new_exclude\n",
    "    \n",
    "    # return max of include, exclude and list1, list2\n",
    "    return (exclude if exclude > include else include, list1 if sum(list1) > sum(list2) else list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e84279a7-35d2-40e9-80ad-cbc4ca546dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request():  \n",
    "    # creating an empty list\n",
    "    requests = []\n",
    "\n",
    "    # number of elements as input\n",
    "    n = int(input(\"Enter number of elements : \"))\n",
    "\n",
    "    # iterating till the range\n",
    "    for i in range(0, n):\n",
    "        element = int(input())\n",
    "\n",
    "        requests.append(element) # adding the element\n",
    "\n",
    "    print(requests)\n",
    "    print ('Maximum duration: ',find_max_sum(requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c6f3c984-887b-4e50-9c4b-2b1635683b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 7\n",
      "30\n",
      "40\n",
      "25\n",
      "50\n",
      "30\n",
      "20\n",
      "70\n",
      "[30, 40, 25, 50, 30, 20, 70]\n",
      "Maximum duration:  (160, [40, 50, 70])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c4aaeca5-63e2-404a-86f3-7a58d6ff40fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 7\n",
      "30\n",
      "40\n",
      "25\n",
      "50\n",
      "30\n",
      "20\n",
      "10\n",
      "[30, 40, 25, 50, 30, 20, 10]\n",
      "Maximum duration:  (110, [40, 50, 20])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e0b19d5f-4690-4e30-9c61-2491c9ff850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 8\n",
      "30\n",
      "40\n",
      "25\n",
      "50\n",
      "30\n",
      "20\n",
      "10\n",
      "40\n",
      "[30, 40, 25, 50, 30, 20, 10, 40]\n",
      "Maximum duration:  (150, [40, 50, 20, 40])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "16fe2e9b-1ad3-4953-87b6-9ff983ffc8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 10\n",
      "30\n",
      "20\n",
      "50\n",
      "40\n",
      "30\n",
      "60\n",
      "70\n",
      "20\n",
      "30\n",
      "50\n",
      "[30, 20, 50, 40, 30, 60, 70, 20, 30, 50]\n",
      "Maximum duration:  (230, [30, 50, 30, 70, 50])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "677f90a9-bb7c-48b5-a506-b767673dccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 3\n",
      "20\n",
      "30\n",
      "5\n",
      "[20, 30, 5]\n",
      "Maximum duration:  (30, [30])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e4b50e26-0600-4512-9c34-1d5091358329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 5\n",
      "20\n",
      "30\n",
      "20\n",
      "50\n",
      "60\n",
      "[20, 30, 20, 50, 60]\n",
      "Maximum duration:  (100, [20, 20, 60])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ee00e9ad-2767-499a-a80a-96f455673281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of elements : 5\n",
      "30\n",
      "20\n",
      "20\n",
      "50\n",
      "20\n",
      "[30, 20, 20, 50, 20]\n",
      "Maximum duration:  (80, [30, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "request()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2Aris",
   "language": "python",
   "name": "hw2aris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
